{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import time\n",
    "import pyodbc    # pip install pyodbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Azure SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define database connection details\n",
    "server   = 'AZURE_SQL_DATABASE_SERVER_NAME'\n",
    "database = 'AZURE_SQL_DATABASE_DATABASE_NAME'\n",
    "username = 'AZURE_SQL_DATABASE_USERNAME'\n",
    "password = 'AZURE_SQL_DATABASE_PASSWORD'\n",
    "driver   = '{ODBC Driver 17 for SQL Server}'\n",
    "\n",
    "# Connect to Azure SQL Database\n",
    "connection = pyodbc.connect(\n",
    "    f'DRIVER={driver};SERVER={server};PORT=1433;DATABASE={database};UID={username};PWD={password};'\n",
    ")\n",
    "\n",
    "# Create a cursor\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Retrieve number of affected datasets by the actual CRUD-Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"\"\"\n",
    "SELECT COUNT(DISTINCT io.SerialNumber)\n",
    "FROM InspectionOperations io\n",
    "WHERE io.ArticleName = 'Mountainbike' AND io.MachineName = 'InspectionMachine1';\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL Query and store the number of affected datasets\n",
    "cursor.execute(sql_query)\n",
    "number_of_processed_datasets = cursor.fetchone()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Run the operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list to store the operation durations for each dataset that is inserted\n",
    "query_durations = []\n",
    "\n",
    "# Number of datasets in the database (e.g., 10,000 after the first iteration)\n",
    "database_record_count = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this use case 10 times per iteration\n",
    "for _ in range(10):\n",
    "\n",
    "    sql_query = f\"\"\"\n",
    "    SELECT \n",
    "        *\n",
    "    FROM \n",
    "        InspectionOperations io\n",
    "    JOIN \n",
    "        Inspections i ON io.InspectionOperationID = i.InspectionOperationID\n",
    "    JOIN \n",
    "        InspectionResults ir ON i.InspectionID = ir.InspectionID\n",
    "    JOIN \n",
    "        InspectionsToSetpoints its ON i.InspectionID = its.InspectionID\n",
    "    JOIN \n",
    "        Setpoints isp ON its.SetpointID = isp.SetpointID\n",
    "    JOIN \n",
    "        InspectionStep ins ON i.InspectionStepID = ins.InspectionStepID\n",
    "    WHERE \n",
    "        io.ArticleName = 'Mountainbike' AND io.MachineName = 'InspectionMachine1'\n",
    "    \"\"\"\n",
    "\n",
    "    # Record the current timestamp before running the operation  \n",
    "    query_start_time = time.time()\n",
    "    \n",
    "    # Run CRUD-Operation\n",
    "    cursor.execute(sql_query)\n",
    "    \n",
    "    # Record the current timestamp after running the operation\n",
    "    query_end_time = time.time()\n",
    "\n",
    "    # Calculate the duration time for this operation\n",
    "    query_duration = query_end_time - query_start_time\n",
    "    query_durations.append(query_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Saving the recorded operation times in the CSV result file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average duration of all operations in this iteration\n",
    "mean_duration = sum(query_durations) / len(query_durations)\n",
    "\n",
    "# Define the dataset to store\n",
    "dataset_to_store = [[\n",
    "    mean_duration,                # Average duration of operations in this iteration\n",
    "    number_of_processed_datasets, # Number of processed datasets\n",
    "    database_record_count         # Current number of datasets in the database\n",
    "]]\n",
    "\n",
    "# Store values in the CSV result file\n",
    "filepath = os.path.join(\"Experiment_Results\", \"select_to_serialnumber.csv\")\n",
    "file_exists = os.path.isfile(filepath)\n",
    "\n",
    "with open(filepath, 'a', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write header if the file does not exist\n",
    "    if not file_exists:\n",
    "        writer.writerow(['DurationTime', 'NumberOfProcessedDatasets', 'NumberOfDatasetsInDatabase'])\n",
    "    \n",
    "    # Append the dataset to the CSV file\n",
    "    writer.writerows(dataset_to_store)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
