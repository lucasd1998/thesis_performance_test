{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import pyodbc    # pip install pyodbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Azure SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define database connection details\n",
    "server   = 'AZURE_SQL_DATABASE_SERVER_NAME'\n",
    "database = 'AZURE_SQL_DATABASE_DATABASE_NAME'\n",
    "username = 'AZURE_SQL_DATABASE_USERNAME'\n",
    "password = 'AZURE_SQL_DATABASE_PASSWORD'\n",
    "driver   = '{ODBC Driver 17 for SQL Server}'\n",
    "\n",
    "# Connect to Azure SQL Database\n",
    "connection = pyodbc.connect(\n",
    "    f'DRIVER={driver};SERVER={server};PORT=1433;DATABASE={database};UID={username};PWD={password};'\n",
    ")\n",
    "\n",
    "# Create a cursor\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Retrieve all currently available serialnumbers in Azure SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve all serialnumbers from Azure SQL Database and store it in a list\n",
    "cursor.execute('SELECT DISTINCT SerialNumber FROM InspectionOperations')\n",
    "serialnumbers = [row.SerialNumber for row in cursor.fetchall()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Run the operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list to store the operation durations for each dataset that is inserted\n",
    "query_durations = []\n",
    "\n",
    "# Number of processed datasets is 1 because only one dataset is affected by the operation in this use case\n",
    "number_of_processed_datasets = 1\n",
    "\n",
    "# Number of datasets in the database (e.g., 10,000 after the first iteration)\n",
    "database_record_count = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this use case 10 times per iteration\n",
    "for _ in range(10):\n",
    "\n",
    "    sql_query = f\"\"\"\n",
    "    UPDATE InspectionOperations\n",
    "    SET UpdateDateTime = GETDATE()\n",
    "    WHERE SerialNumber = '{random.choice(serialnumbers)}';\n",
    "    \"\"\"\n",
    "\n",
    "    # Record the current timestamp before running the operation  \n",
    "    query_start_time = time.time()\n",
    "    \n",
    "    # Run the CRUD-operation\n",
    "    cursor.execute(sql_query)\n",
    "    \n",
    "    # Record the current timestamp after running the operation\n",
    "    query_end_time = time.time()\n",
    "\n",
    "    # Calculate the duration time for this operation\n",
    "    query_duration = query_end_time - query_start_time\n",
    "    query_durations.append(query_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Saving the recorded operation times in the CSV result file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average duration of all operations in this iteration\n",
    "mean_duration = sum(query_durations) / len(query_durations)\n",
    "\n",
    "# Define the dataset to store\n",
    "dataset_to_store = [[\n",
    "    mean_duration,                # Average duration of operations in this iteration\n",
    "    number_of_processed_datasets, # Number of processed datasets (1 in this case, since 10,000 datasets are inserted sequentially)\n",
    "    database_record_count         # Number of datasets in the database after inserting 10,000 datasets\n",
    "]]\n",
    "\n",
    "# Store values in the CSV result file\n",
    "filepath = os.path.join(\"Experiment_Results\", \"select_to_serialnumber.csv\")\n",
    "file_exists = os.path.isfile(filepath)\n",
    "\n",
    "with open(filepath, 'a', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write header if the file does not exist\n",
    "    if not file_exists:\n",
    "        writer.writerow(['DurationTime', 'NumberOfProcessedDatasets', 'NumberOfDatasetsInDatabase'])\n",
    "    \n",
    "    # Append the dataset to the CSV file\n",
    "    writer.writerows(dataset_to_store)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
